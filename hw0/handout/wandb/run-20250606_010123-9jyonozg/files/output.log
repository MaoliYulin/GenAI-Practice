Using cuda device
Shape of X [B, C, H, W]: torch.Size([8, 3, 256, 256])
Shape of y: torch.Size([8]) torch.int64
NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (1): Permute()
    (2): LayerNorm((64, 64, 128), eps=1e-05, elementwise_affine=True)
    (3): Permute()
    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (5): Permute()
    (6): LayerNorm((64, 64, 128), eps=1e-05, elementwise_affine=True)
    (7): Permute()
    (8): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    (9): GELU(approximate='none')
    (10): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
    (11): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (12): Flatten(start_dim=1, end_dim=-1)
    (13): Linear(in_features=131072, out_features=3, bias=True)
  )
)

Epoch 1
-------------------------------
Traceback (most recent call last):
  File "E:\Document\cmu course\Semester 3\elective\10623\hw0\handout\img_classifier.py", line 202, in <module>
    main(args.n_epochs, args.batch_size, args.learning_rate)
  File "E:\Document\cmu course\Semester 3\elective\10623\hw0\handout\img_classifier.py", line 180, in main
    train_one_epoch(train_dataloader, model, loss_fn, optimizer, t)
  File "E:\Document\cmu course\Semester 3\elective\10623\hw0\handout\img_classifier.py", line 133, in train_one_epoch
    pred = model(X)
  File "D:\anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "D:\anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "E:\Document\cmu course\Semester 3\elective\10623\hw0\handout\img_classifier.py", line 124, in forward
    logits = self.linear_relu_stack(x)
  File "D:\anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "D:\anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\container.py", line 250, in forward
    input = module(input)
  File "D:\anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "D:\anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "D:\anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\conv.py", line 549, in _conv_forward
    return F.conv2d(
RuntimeError: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [8, 196608]
